data = "./weights/embeddings/"
mode = "spatial_palette"
[wandb]
mode = "online" # "online", "offline", "disabled"
entity = "piercus"
project = "color-palette"
name = "spatial-encoder-cubic-lr-1e-5"
tags = ["spatial-encoder", "embeddings"]

[sd]
unet = "weights/models/unet.safetensors"
text_encoder = "weights/models/CLIPTextEncoderL.safetensors"
lda = "weights/models/lda.safetensors"

[latent_diffusion]
unconditional_text_sampling_probability = 0.0
offset_noise = 0.1
cubic = true

[ip_adapter]
embedding_dim = 10

[spatial_palette_encoder]
feedforward_dim = 20
num_layers = 2
num_attention_heads = 2
mode = 'transformer'
weighted_palette = false
learning_rate = 1e-5

[training]
duration = "80:epoch"
seed = 0
batch_size = 20
gradient_accumulation = "3:step"
# clip_grad_norm = 1.0
# clip_grad_value = 1.0
evaluation_interval = "10:epoch"
evaluation_seed = 1
# num_workers = 8
# use_color_loss = false
device="cuda:0"
dtype="bfloat16"

[monitor_gradient]
patterns = ["ip_adapter.*"]

[optimizer]
optimizer = "AdamW" # "SGD", "Adam", "AdamW", "AdamW8bit", "Lion8bit"
learning_rate = 1e-4
betas = [0.9, 0.999]
eps = 1e-8
weight_decay = 1e-2

[lr_scheduler]
type = "ConstantLR"
update_interval = "1:step"
warmup = "500:step"

[dataset]
hf_repo = "refiners/unsplash-25k-cogvlm-captions"
revision = "main"
resize_image_max_size = 512
split = "train[200:1200]"

[eval_dataset]
hf_repo = "refiners/unsplash-25k-cogvlm-captions"
revision = "main"
resize_image_max_size = 512
split = "train[200:250]"

[offload_to_cpu]
use = true

[visual_evaluation]
batch_size = 12
condition_scale = 7.5
db_indexes=[0, 1, 2, 3, 4, 5]
use = true
use_unconditional_text_embedding = false

[grid_evaluation]
# batch_size = 12
# color_bits = 4
# db_indexes = [0, 1, 2]#, 6, 7, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
# prompts = [
#      "A Bustling City Street",
#      "A cute cat",
#      #"An oil painting",
#      #"A photography of a beautiful woman",
#     # "A pair of shoes",
#     # "A group of working people"
# ]
# condition_scale = 7.5
# use_unconditional_text_embedding = false
use = false

[mmd_evaluation]
batch_size = 12
condition_scale = 7.5
use = true
use_unconditional_text_embedding = false

[timestep_loss_rescaler]
use = true